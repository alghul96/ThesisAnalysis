library(hybridHclust)
plot(WardClusters, labels = other_info$immyear, which.plot = 2)
identify(WardClusters, mostFollowed) # click over a branch to see the most followed courses!
comparison = cbind(courses_mixtgroup[2:3], courses_kmeagroup[2:1], courses_hgroup[1:2], courses_kmedgroup[1:2])
comparison = cbind(courses_mixtgroup[2:3], courses_kmeagroup[2:1], courses_hgroup[1:2], courses_kmedgroup[1:2])
round(comparison, 2) # comparing the two major clusters
round(comparison, 2) # comparing the two major clusters
par(mfrow = c(3,1))
image(round(t(kcenters)), axes = FALSE, main = "K-means Centroids")
abline(h = c(.25, .75), col = 0)
text(x = .8, y = seq(0, 1, l = 3), labels = c("Sist. e Reti", "Intell. Art.", "Vecchio Ord."), col = "0")
image(mixtprototypes[, c(3,2,1)], axes = FALSE, main = "Mixture-Model Prototypes")
abline(h = c(.25, .75), col = 0)
text(x = .8, y = seq(0, 1, l = 3), labels = c("Sist. e Reti", "Intell. Art.", "Vecchio Ord."), col = "0")
image(t(clusterdataf[kmedoidsClusters$medoids,]), axes = FALSE, main = "K-medoids Medoids")
abline(h = c(.25, .75), col = 0)
text(x = .8, y = seq(0, 1, l = 3), labels = c("Sist. e Reti", "Intell. Art.", "Vecchio Ord."), col = "0")
for(i in results){
print("_________________________")
print(cluster.stats(distances, i))
plot(silhouette(i, distances), cex.names=0.6)
}
par(mfrow = c(2,2))
for(i in results){
hist(i, main = "")
}
comparison = cbind(courses_mixtgroup[2:3], courses_kmeagroup[2:1], courses_hgroup[1:2], courses_kmedgroup[1:2])
plot(silhouette(temp, distances))
temp = clusterboot(clusterdataf, clustermethod = kmeansCBI, krange = 3)
plot(temp)
temp = temp$result$partition
mostFollowed_byclust(temp, .5)
plot(silhouette(temp, distances))
rm(temp)
temp = clusterboot(clusterdataf, clustermethod = kmeansCBI, krange = 3)
plot(temp)
temp = temp$result$partition
par(mfrow = c(1,3))
for(i in 1:3){
print(cluster.stats(distances, kmeansClusters_rep[[i]]@cluster))
plot(silhouette(kmeansClusters_rep[[i]]@cluster, distances), cex.names=0.6)
}
library(spatstat)
plot(
as.im(as.matrix(courses_mixtgroup),
W = owin(c(1,90), c(1,140))),
main = "Courses Frequencies Beetween Clusters")
plot(
as.im(as.matrix(courses_mixtgroup),
W = owin(c(1,90), c(1,140))),
main = "Courses Frequencies Beetween Clusters")
ls
ls()
library("arulesViz", lib.loc="~/R/win-library/3.3")
library("arules", lib.loc="~/R/win-library/3.3")
detach("package:arules", unload=TRUE)
detach("package:arulesViz", unload=TRUE)
remove.packages("arules", lib="~/R/win-library/3.3")
remove.packages("arulesViz", lib="~/R/win-library/3.3")
datafexam[, mostFollowed_byclust(rep(1, 322)) > 0.3 & mostFollowed_byclust(rep(1, 322)) < 1]
datafexam[, mostFollowed_byclust(rep(1, 322)) > 0.0 & mostFollowed_byclust(rep(1, 322)) < 1]
datafexam_reduced = datafexam[, mostFollowed_byclust(rep(1, 322)) > 0.0 & mostFollowed_byclust(rep(1, 322)) < 1]
datafexam_reduced
dim(datafexam_reduced)
dim(datafexam)
kgroup_3
kgroup_3$2
kgroup_3 == 2
hist(kgroup_3)
names(datafexam)(kgroup_3 == 3)
names(datafexam)[kgroup_3 == 3]
row.names(datafexam)[kgroup_3 == 3]
row.names(datafexam) < 00004
row.names(datafexam) < 00003
row.names(datafexam) < 00002
row.names(datafexam) < 00001
numeric(row.names(datafexam)) < 00001
numeric(row.names(datafexam))
as.numeric(row.names(datafexam))
as.numeric(row.names(datafexam)) < 400000
sum(as.numeric(row.names(datafexam)) < 400000)
row.names(datafexam)[kgroup_3 == 3]
row.names(datafexam)[hgroup_3 == 3]
row.names(datafexam)[mixtgroup_3 == 3]
row.names(datafexam)[mixtgroup_3 == 2]
row.names(datafexam)[mixtgroup_3 == 1]
as.numeric(row.names(datafexam)) < 400000
row.names(datafexam)[as.numeric(row.names(datafexam))] < 400000
row.names(datafexam)[as.numeric(row.names(datafexam)) < 400000]
row.names(datafexam)[as.numeric(row.names(datafexam)) < 400000] in row.names(datafexam)[kgroup_3 == 3]
row.names(datafexam)[as.numeric(row.names(datafexam)) < 400000] == row.names(datafexam)[kgroup_3 == 3]
row.names(datafexam)[as.numeric(row.names(datafexam)) < 400000]
row.names(datafexam)[kgroup_3 == 3]
row.names(datafexam)["0000223891"]
other_info["0000223891"]
other_info["0000223891",]
hist(other_info$mixtgroup)
other_info["0000358005",]
mixtprob
other_info["0000358005",]
row.names(datafexam)[as.numeric(row.names(datafexam)) < 400000] == row.names(datafexam)[kgroup_3 == 3]
row.names(datafexam)[as.numeric(row.names(datafexam)) < 400000] in row.names(datafexam)[kgroup_3 == 3]
row.names(datafexam)[as.numeric(row.names(datafexam)) < 400000] %in% row.names(datafexam)[kgroup_3 == 3]
row.names(datafexam)[as.numeric(row.names(datafexam)) < 400000] %!in% row.names(datafexam)[kgroup_3 == 3]
row.names(datafexam)[as.numeric(row.names(datafexam)) < 400000] !%in% row.names(datafexam)[kgroup_3 == 3]
!(row.names(datafexam)[as.numeric(row.names(datafexam)) < 400000] %in% row.names(datafexam)[kgroup_3 == 3])
row.names(datafexam)[!(row.names(datafexam)[as.numeric(row.names(datafexam)) < 400000] %in% row.names(datafexam)[kgroup_3 == 3])]
!(row.names(datafexam)[as.numeric(row.names(datafexam)) < 400000] %in% row.names(datafexam)[kgroup_3 == 3])
!(row.names(datafexam)[as.numeric(row.names(datafexam)) < 400000] %in% row.names(datafexam)[kgroup_3 == 3])
row.names(datafexam)[as.numeric(row.names(datafexam)) < 400000]
cbind(row.names(datafexam)[as.numeric(row.names(datafexam)) < 400000], !(row.names(datafexam)[as.numeric(row.names(datafexam)) < 400000] %in% row.names(datafexam)[kgroup_3 == 3]))
row.names(datafexam)[as.numeric(row.names(datafexam)) < 400000]
row.names(datafexam)[as.numeric(row.names(datafexam)) < 39000]
row.names(datafexam)[as.numeric(row.names(datafexam)) < 39000]
row.names(datafexam)[as.numeric(row.names(datafexam)) < 390000]
row.names(datafexam)[as.numeric(row.names(datafexam)) < 390000]
datafexam[as.numeric(row.names(datafexam)) < 390000, ]
row.names(datafexam)[kgroup_3 == 3]
datafexam_reduced = datafexam[as.numeric(row.names(datafexam)) < 390000, ] # Removing older students
datafexam_reduced
dim(datafexam_reduced)
datafexam_reduced = datafexam_reduced[, mostFollowed_byclust(rep(1, 322)) > 0.0 & mostFollowed_byclust(rep(1, 322)) < 1] # Removing unecessary exams
dim(datafexam_reduced)
datafexam_reduced = datafexam[as.numeric(row.names(datafexam)) > 390000, ] # Removing older students
dim(datafexam_reduced)
datafexam_reduced = datafexam_reduced[, mostFollowed_byclust(rep(1, 322)) > 0.0 & mostFollowed_byclust(rep(1, 322)) < 1] # Removing unecessary exams
dim(datafexam_reduced)
frequency(datafexam)
frequency(datafexam[,])
frequency(datafexam[,1])
frequency(datafexam[,3])
apply(datafexam, 2, mean)
datafexam_reduced = datafexam[as.numeric(row.names(datafexam)) > 390000, ] # Removing older students
exams_frequencies = apply(datafexam_reduced, 2, mean)
exams_frequencies
dim(datafexam_reduced)
rm(exam_frequencies)
exams_frequencies_reduced = apply(datafexam_reduced, 2, mean)
exams_frequencies_reduced < 0
exams_frequencies_reduced = 0
exams_frequencies_reduced = apply(datafexam_reduced, 2, mean)
exams_frequencies_reduced == 0
exams_frequencies
rm(exams_frequencies)
exams_frequencies_reduced > 0 & exams_frequencies < 1
exams_frequencies_reduced > 0 & exams_frequencies_reduced < 1
exams_frequencies_reduced
apply(datafexam, 2, mean)
datafexam_reduced = datafexam[as.numeric(row.names(datafexam)) > 390000, ] # Removing older students
exams_frequencies_reduced = apply(datafexam_reduced, 2, mean)
datafexam_reduced = datafexam_reduced[, exams_frequencies_reduced > 0 & exams_frequencies_reduced < 1] # Removing unecessary exams
dim(datafexam_reduced)
dim(datafexam_reduced)
apply(datafexam_reduced, 2, mean)
dim(datafexam_reduced)
kmeansClusters_rep_reduced = stepFlexclust(datafexam_reduced, k = 2:10, nrep = 800, FUN = cclust, multicore = TRUE)
library(flexclust)
kmeansClusters_rep_reduced = stepFlexclust(datafexam_reduced, k = 2:10, nrep = 800, FUN = cclust, multicore = TRUE)
plot(kmeansClusters_rep_reduced) # from the within sum of squares, we see that it become stable after 2/3 clusters
par(mfrow = c(1,3))
for(i in 1:3){
print(cluster.stats(distances, kmeansClusters_rep_reduced[[i]]@cluster))
plot(silhouette(kmeansClusters_rep_reduced[[i]]@cluster, distances), cex.names=0.6)
}
library(fpc)
for(i in 1:3){
print(cluster.stats(distances, kmeansClusters_rep_reduced[[i]]@cluster))
plot(silhouette(kmeansClusters_rep_reduced[[i]]@cluster, distances), cex.names=0.6)
}
par(mfrow = c(1,3))
for(i in 1:3){
print(cluster.stats(distances, kmeansClusters_rep_reduced[[i]]@cluster))
plot(silhouette(kmeansClusters_rep_reduced[[i]]@cluster, distances), cex.names=0.6)
}
distances_reduced = daisy(as.factor.dataframe(datafexam_reduced),
type = list(asymm = c(1:ncol(clusterdataf))), # threating the variables as asymmetric binaries
metric = "gower")
library(cluster)
distances_reduced = daisy(as.factor.dataframe(datafexam_reduced),
type = list(asymm = c(1:ncol(clusterdataf))), # threating the variables as asymmetric binaries
metric = "gower")
distances_reduced = daisy(datafexam_reduced,
type = list(asymm = c(1:ncol(clusterdataf))), # threating the variables as asymmetric binaries
metric = "gower")
distances_reduced = daisy(datafexam_reduced,
type = list(asymm = c(1:ncol(datafexam_reduced))), # threating the variables as asymmetric binaries
metric = "gower")
for(i in 1:3){
print(cluster.stats(distances, kmeansClusters_rep_reduced[[i]]@cluster))
plot(silhouette(kmeansClusters_rep_reduced[[i]]@cluster, distances_reduced), cex.names=0.6)
}
for(i in 1:3){
print(cluster.stats(distances_reduced, kmeansClusters_rep_reduced[[i]]@cluster))
plot(silhouette(kmeansClusters_rep_reduced[[i]]@cluster, distances_reduced), cex.names=0.6)
}
WardClusters_reduced = hclust(distances_reduced, method = "ward.D")
plot(WardClusters_reduced)
plot(WardClusters_reduced)
plot(WardClusters_reduced, labels = other_info$immyear)
WardClusters_reduced = hclust(distances_reduced, method = "ward.D")
plot(WardClusters_reduced, labels = other_info$immyear)
plot(WardClusters_reduced)
plot(WardClusters_reduced, labels = other_info$immyear)
plot(WardClusters_reduced, labels = F)
identify(WardClusters, mostFollowed) # click over a branch to see the most followed courses!
rm cod
rm(cod)
rm(dend)
mostFollowed_byclust = function(clustergroup, X = clusterdataf, percentage = 0.7, graph = TRUE, verbose = TRUE){
cluster_number = levels(factor(clustergroup))
if(graph == TRUE) hist(clustergroup, main = "Distribution of clusters", breaks = length(cluster_number), col = "lightblue")
exam_per_group = data.frame(row.names = colnames(X))
for(i in 1:length(cluster_number)){
k = clustergroup == as.numeric(i) # select the cluster instances
course_freq = apply(X[k, ], 2, mean)
is_popular = (course_freq >= percentage) & (course_freq <= 1) # selecting more frequent courses
most_followed = course_freq[is_popular] # selection of the courses
most_followed_ordered = most_followed[order(course_freq[is_popular], decreasing = T)] # ordering
exam_per_group[,i] = course_freq
if (verbose == TRUE){
print(paste("Group ", i, "of dimention", length(names(X)[k == T])))
print(as.data.frame(most_followed_ordered))
cat("____________________________________________________________________\n")
}
}
return(exam_per_group)
}
mostFollowed_byclust(kgroup_3)
as.factor.dataframe(clusterdataf)
rm(carriere)
clusterdataf = datafexam_reduced
dim(datafexam_reduced)
clusterdataf = datafexam_reduced
kmeansClusters_rep_reduced = stepFlexclust(clusterdataf, k = 2:10, nrep = 800, FUN = cclust, multicore = TRUE)
plot(kmeansClusters_rep_reduced) # from the within sum of squares, we see that it become stable after 2/3 clusters
library(flexclust)
clusterdataf = datafexam_reduced
kmeansClusters_rep_reduced = stepFlexclust(clusterdataf, k = 2:10, nrep = 800, FUN = cclust, multicore = TRUE)
plot(kmeansClusters_rep_reduced) # from the within sum of squares, we see that it become stable after 2/3 clusters
for(i in 1:3){
print(cluster.stats(distances_reduced, kmeansClusters_rep_reduced[[i]]@cluster))
plot(silhouette(kmeansClusters_rep_reduced[[i]]@cluster, distances_reduced), cex.names=0.6)
}
library(fcp)
library(fpc)
for(i in 1:3){
print(cluster.stats(distances_reduced, kmeansClusters_rep_reduced[[i]]@cluster))
plot(silhouette(kmeansClusters_rep_reduced[[i]]@cluster, distances_reduced), cex.names=0.6)
}
library(stepflexclust)
library(cluster)
for(i in 1:3){
print(cluster.stats(distances_reduced, kmeansClusters_rep_reduced[[i]]@cluster))
plot(silhouette(kmeansClusters_rep_reduced[[i]]@cluster, distances_reduced), cex.names=0.6)
}
mostFollowed_byclust(kmeansClusters_rep_reduced[[1]]$cluster)
kmeansClusters_rep_reduced[[1]]$cluster
kmeansClusters_rep_reduced[[2]]
kmeansClusters_rep_reduced[[1]]
kmeansClusters_rep_reduced[[1][2]]
kmeansClusters_rep_reduced[[1][1]]
kmeansClusters_rep_reduced[[1],[1]]
kmeansClusters_rep_reduced[[1],2]
kmeansClusters_rep_reduced[[1]]
kmeansClusters_rep_reduced[[1]][2]
kmeansClusters_rep_reduced[[1]][1]
kmeansClusters_rep_reduced[[1]]$clusters
temp = kmeansClusters_rep_reduced[[1]]
temp
temp$n
temp$cluster
temp[1]
rm(temp)
mostFollowed_byclust(kmeansClusters_rep_reduced[[1]]@cluster)
mostFollowed_byclust(kmeansClusters_rep_reduced[[1]]@cluster, percentage = 0.5)
distances_reduced = daisy(as.factor.dataframe(clusterdataf),
type = list(asymm = c(1:ncol(datafexam_reduced))), # threating the variables as asymmetric binaries
metric = "gower")
WardClusters_reduced = hclust(distances_reduced, method = "ward.D")
plot(WardClusters_reduced, labels = F)
identify(WardClusters_reduced, FUN = mostFollowed)
identify(WardClusters_reduced, FUN = mostFollowed)
HybridClusters_reduced =  hybridHclust(clusterdataf)
library(hybridHclust)
HybridClusters_reduced =  hybridHclust(clusterdataf)
plot(HybridClusters_reduced, labels = F)
identify(Hybridclusters_reduced, FUN = mostFollowed)
identify(HybridClusters_reduced, FUN = mostFollowed)
identify(HybridClusters_reduced, FUN = mostFollowed)
?PythonInR
clusterdataf = datafexam_reduced
setwd("D:/Box Sync/#UNI/Materiale tesi/Analysis/ThesisAnalysis/Python")
pyConnect() # connecting to python session
library(PythonInR)
setwd("D:/Box Sync/#UNI/Materiale tesi/Analysis/ThesisAnalysis/Python")
pyConnect() # connecting to python session
pySet(data, value = clusterdataf)
pySet("data", value = clusterdataf)
pyExecfile("model-based.py") # do not run
pySet("data", value = as.factor.dataframe(clusterdataf))
clusterdataf = as.factor.dataframe(datafexam_reduced)
pySet("data", value = clusterdataf)
str(clusterdataf)
pySet("data", value = clusterdataf)
clusterdataf = datafexam_reduced
pySet("data", value = clusterdataf)
pyExecfile("model-based.py") # do not run
pySet("data", value = clusterdataf, usePandas = TRUE)
pyExecfile("model-based.py") # do not run
pyExec("import pandas")
pySet("data", value = clusterdataf, usePandas = TRUE)
pyExecfile("model-based.py") # do not run
mixtgroup_reduced = pyGet("modelclust", simplify = FALSE) + 1
pyExit()
mixtgroup_reduced
str(mixtgroup_reduced)
hist(mixtgroup_reduced)
most_frequented_byclust(mixtgroup_reduced)
mostFollowed_byclust(mixtgroup_reduced)
cbind(rownames(datafexam_reduced))
cbind(rownames(datafexam_reduced, mixtgroup_reduced))
cbind(rownames(datafexam_reduced), mixtgroup_reduced)
mostFollowed_byclust(mixtgroup_reduced) == 2
cbind(rownames(datafexam_reduced), mixtgroup_reduced) == 2
cbind(rownames(datafexam_reduced), mixtgroup_reduced)
?list
most_frequented_byclust
results
most_frequented_byclust
most_frequented_byclust = courses_mixtgroup[apply(courses_mixtgroup, 1, sum) > 0.3, 2:3]
most_frequented_byclust
other_info[,3]
courses_mixtgroup
most_frequented_byclust = courses_mixtgroup[apply(courses_mixtgroup, 1, sum) > 0.3,]
most_frequented_byclust
courses_mixtgroup_red = mostFollowed_byclust(mixtgroup_reduced, X = datafexam_reduced)
courses_mixtgroup_red = mostFollowed_byclust(mixtgroup_reduced, X = datafexam_reduced, verbose = F)
courses_mixtgroup_red
pyConnect() # connecting to python session
pyExec("import pandas")
pySet("data", value = clusterdataf, usePandas = TRUE)
pyExecfile("model-based.py") # do not run
mixtgroup_reduced = pyGet("modelclust", simplify = FALSE) + 1
pyExit()
wd()
library(PythonInR)
clusterdataf = datafexam_reduced
pyConnect() # connecting to python session
pyExec("import pandas")
pySet("data", value = clusterdataf, usePandas = TRUE)
pyExecfile("model-based.py") # do not run
mixtgroup_reduced = pyGet("modelclust", simplify = FALSE) + 1
pyExit()
library(PythonInR)
setwd("D:/Box Sync/#UNI/Materiale tesi/Analysis/ThesisAnalysis/Python")
pyConnect() # connecting to python session
pyExec("import pandas")
pySet("data", value = clusterdataf, usePandas = TRUE)
pyExecfile("model-based.py") # do not run
mixtgroup_reduced = pyGet("modelclust", simplify = FALSE) + 1
pyExit()
courses_mixtgroup_red = mostFollowed_byclust(mixtgroup_reduced, X = datafexam_reduced, verbose = F)
courses_mixtgroup_red
ls()
monagroup
rm(arules)
ls()
library(externalfunctions)
hist(courses_mixtgroup)
plot(courses_mixtgroup)
courses_mixtgroup_red = mostFollowed_byclust(mixtgroup_reduced, X = datafexam_reduced, verbose = F)
plot(courses_mixtgroup)
courses_mixtgroup_red
plot(courses_mixtgroup_red)
plot(
as.im(as.matrix(courses_mixtgroup_red),
W = owin(c(1,90), c(1,140))),
main = "Courses Frequencies Beetween Clusters")
library(spatstat)
plot(
as.im(as.matrix(courses_mixtgroup_red),
W = owin(c(1,90), c(1,140))),
main = "Courses Frequencies Beetween Clusters")
most_frequented_byclust = courses_mixtgroup_red[apply(courses_mixtgroup_red, 1, sum) > 0.2,]
most_frequented_byclust = courses_mixtgroup[apply(courses_mixtgroup, 1, sum) > 0.3,]
most_frequented_byclust_red = courses_mixtgroup_red[apply(courses_mixtgroup_red, 1, sum) > 0.2,]
most_frequented_byclust_red
detach("package:arules")
detach("arules")
sessionInfo()
detach(lattice)
most_frequented_byclust_red = courses_mixtgroup_red[apply(courses_mixtgroup_red, 1, sum) > 0.2,]
most_frequented_byclust_red
ComplClusters_reduced = hclust(distances_reduced, method = "complete")
plot(ComplClusters_reduced, labels = F)
rm(ComplClusters)
pc
?pamk
library(flexclust)
library(fpc)
library(cluster)
?pamk
pamk(distances_reduced, krange = 1:14, criterion = "asw", diss = TRUE)
pamk(distances_reduced, krange = 1:14, criterion = "asw", diss = TRUE)
pc_reduce = pamk(distances_reduced, krange = 1:14, criterion = "asw", diss = TRUE)
kmedgroup_reduced = pc_reduce$pamobject$cluster
mostFollowed_byclust(kmedgroup_reduced)
kmeansClusters_rep_reduced
kmeansClusters_rep_reduced[3]
kmeansClusters_rep_reduced[[3]]
kmeansClusters_rep_reduced[[2]]
kmeansClusters_rep_reduced[[3]]
kmeansClusters_rep_reduced = stepFlexclust(clusterdataf, k = 2:8, nrep = 1000, FUN = cclust, multicore = TRUE)
kmeansClusters_rep_reduced[[2]]
kmeansClusters_rep_reduced[[3]]
mostFollowed_byclust(kmeansClusters_rep_reduced[[3]])
mostFollowed_byclust(kmeansClusters_rep_reduced[[3]]@cluster, percentage = .5)
mostFollowed_byclust(kmeansClusters_rep_reduced[[2]]@cluster, percentage = .5) # 3 clusters
mostFollowed_byclust(kmeansClusters_rep_reduced[[3]]@cluster, percentage = .5) # 4 clusters
mostFollowed_byclust(kmeansClusters_rep_reduced[[2]]@cluster, percentage = .5) # 3 clusters
mostFollowed_byclust(kmeansClusters_rep_reduced[[3]]@cluster, percentage = .5) # 4 clusters
mostFollowed_byclust(kmeansClusters_rep_reduced[[3]]@cluster, percentage = .5) # 4 clusters
stepflexclust
type(clusterdataf)
class(clusterdataf)
library(cluster)
kmeans()
kmeans
c("Ciao", "ok")
class(c("ciao, ok"))
class(c("ciao", "ok"))
list("ciao", "ok")
ciao %in% list("ciao", "ok")
"ciao" %in% list("ciao", "ok")
class(list("ciao", "ok"))
?stop
studyplan_finder = function(binarydataf, technique, nclust, return_class = TRUE){
if(class(binarydataf) != "data.frame") warning("Input should be a binary data frame.")
if(class(technique) != "list") stop("Should provide a list of valid clustering techniques.")
if(nclust == 0) stop("At least one cluster is needed to perform analysis.")
}
studyplan_finder(clusterdataf, technique = list("ciao"), nclust = 0)
studyplan_finder(clusterdataf, technique = list("ciao"), nclust = 1)
studyplan_finder = function(binarydataf, technique, nclust, nsim = 1, return_class = TRUE){
library(flexclust)
library(cluster)
library(fpc)
if(class(binarydataf) != "data.frame") warning("Input should be a binary data frame.")
if(class(technique) != "list") stop("Should provide a list of valid clustering techniques. At least one technique is required.")
if(nclust == 0) stop("At least one cluster is needed to perform analysis.")
# K - means
if("kmeans" %in% technique){
print("\nPerforming k-means clustering. It might take a while depending on number of simulations...")
}
}
studyplan_finder(clusterdataf, technique = list("ciao"), nclust = 1)
studyplan_finder = function(binarydataf, technique, nclust, nsim = 1, return_class = TRUE){
library(flexclust)
library(cluster)
library(fpc)
if(class(binarydataf) != "data.frame") warning("Input should be a binary data frame.")
if(class(technique) != "list") stop("Should provide a list of valid clustering techniques. Please input a list of techniques.")
if(!(technique %in% list("k-means"))) stop("Should provide a list of valid clustering techniques.")
if(nclust == 0) stop("At least one cluster is needed to perform analysis.")
# K - means
if("k-means" %in% technique){
print("\nPerforming k-means clustering. It might take a while depending on number of simulations...")
}
}
studyplan_finder(clusterdataf, technique = list("ciao"), nclust = 1)
studyplan_finder = function(binarydataf, technique, nclust, nsim = 1, return_class = TRUE){
library(flexclust)
library(cluster)
library(fpc)
if(class(binarydataf) != "data.frame") warning("Input should be a binary data frame.")
if(class(technique) != "list") stop("Should provide a list of valid clustering techniques. Please input a list of techniques.")
if(!(technique %in% list("k-means"))) stop("Should provide a list of valid clustering techniques, e.g. list('k-means')")
if(nclust == 0) stop("At least one cluster is needed to perform analysis.")
# K - means
if("k-means" %in% technique){
print("\nPerforming k-means clustering. It might take a while depending on number of simulations...")
}
}
studyplan_finder(clusterdataf, technique = list("k-means"), nclust = 1)
studyplan_finder = function(binarydataf, technique, nclust, nsim = 1, return_class = TRUE){
library(flexclust)
library(cluster)
library(fpc)
if(class(binarydataf) != "data.frame") warning("Input should be a binary data frame.")
if(class(technique) != "list") stop("Should provide a list of valid clustering techniques. Please input a list of techniques.")
if(!(technique %in% list("k-means"))) stop("Should provide a list of valid clustering techniques, e.g. list('k-means')")
if(nclust == 0) stop("At least one cluster is needed to perform analysis.")
# K - means
if("k-means" %in% technique){
cat("Performing k-means clustering. It might take a while depending on number of simulations...\n")
}
}
studyplan_finder(clusterdataf, technique = list("k-means"), nclust = 1)
studyplan_finder = function(binarydataf, technique, nclust, nsim = 1, return_class = TRUE){
library(flexclust)
library(cluster)
library(fpc)
if(class(binarydataf) != "data.frame") warning("Input should be a binary data frame.")
if(class(technique) != "list") stop("Should provide a list of valid clustering techniques. Please input a list of techniques.")
if(!(technique %in% list("k-means"))) stop("Should provide a list of valid clustering techniques, e.g. list('k-means')")
if(nclust == 0) stop("At least one cluster is needed to perform analysis.")
# K - means
if("k-means" %in% technique){
cat("\nPerforming k-means clustering. It might take a while depending on number of simulations...")
}
}
studyplan_finder(clusterdataf, technique = list("k-means"), nclust = 1)
