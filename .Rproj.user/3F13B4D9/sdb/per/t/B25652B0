{
    "collab_server" : "",
    "contents" : "library(flexclust)\nlibrary(cluster)\nlibrary(fpc)\nlibrary(hybridHclust)\n\n#### AS FACTOR DATAFRAME #####\n\nas.factor.dataframe = function(x){\n  \n  output_dataframe = data.frame(row.names = rownames(x))\n  \n  for(i in names(x)){\n    \n        output_dataframe[, i] = factor(x[ ,i])\n    \n  }\n  return(output_dataframe) \n}\n\n\n#### MOST FOLLOWED #####\n\nmostFollowed = function(k, percentage = 0.7){\n  \n  course_freq = apply(clusterdataf[k, ], 2, mean)\n  is_popular = (course_freq >= percentage) & (course_freq <= 1) # seeing which courses are more frequent\n  \n  most_followed = course_freq[is_popular] # selection of the courses\n  most_followed_ordered = most_followed[order(course_freq[is_popular], decreasing = T)] # ordering\n  \n  print(length(k))\n  print(as.data.frame(most_followed_ordered))\n  cat(\"____________________________________________________________________\\n\")\n  \n}\n\n#### MOST FOLLOWED BYCLUST  #####\n\n\nmostFollowed_byclust = function(clustergroup, X = clusterdataf, percentage = 0.7, graph = TRUE, verbose = TRUE){\n  \n  cluster_number = levels(factor(clustergroup))\n  \n  if(graph == TRUE) hist(clustergroup, main = \"Distribution of clusters\", breaks = length(cluster_number), col = \"lightblue\")\n  \n  exam_per_group = data.frame(row.names = colnames(X))\n  \n  for(i in 1:length(cluster_number)){\n    \n    k = clustergroup == as.numeric(i) # select the cluster instances\n  \n    course_freq = apply(X[k, ], 2, mean) # compute the frequencies of group k in dataframe\n    is_popular = (course_freq >= percentage) & (course_freq <= 1) # selecting more frequent courses\n    \n    most_followed = course_freq[is_popular] # selection of the courses\n    most_followed_ordered = most_followed[order(course_freq[is_popular], decreasing = T)] # ordering\n    \n    exam_per_group[,i] = course_freq\n    \n    if (verbose == TRUE){\n      print(paste(\"Group \", i, \"of dimention\", length(names(X)[k == T])))\n      print(as.data.frame(most_followed_ordered))\n      cat(\"____________________________________________________________________\\n\")\n    }\n\n    \n  }\n  \n  return(exam_per_group)\n  \n}\n\n\n#### STUDYPLAN FINDER #####\n\nstudyplan_finder = function(binarydataf, technique, nclust, nsim = 1){\n  \n  if(class(binarydataf) != \"data.frame\") warning(\"Input should be a binary data frame.\")\n  if(class(technique) != \"list\") stop(\"Should provide a list of valid clustering techniques. Please input a list of techniques.\")\n  if(length(nclust) == 1) if(nclust == 0) stop(\"At least one cluster is needed to perform analysis.\")\n  \n  results = list()\n  \n  \n  cat(\"\\nComputing distance matrix for binary variables...\\n\")\n  distances = daisy(binarydataf, \n                    type = list(asymm = c(1:ncol(binarydataf))), # threating the variables as asymmetric binaries\n                    metric = \"gower\")\n  \n  \n  # K - means\n  if(\"k-means\" %in% technique){\n    cat(\"\\nPerforming k-means clustering. It might take a while depending on number of simulations...\\n\")\n    kmeans_result = stepFlexclust(binarydataf, k = nclust, nrep = nsim, FUN = cclust, multicore = TRUE, verbose = FALSE)\n    results[\"kmeans\"] = list(kmeans_result)\n    \n  }\n  \n  \n  # K-medoids\n  if(\"k-medoids\" %in% technique){\n    cat(\"\\nPerforming k-medoids clustering...\\n\")\n    kmedoids_result = pamk(distances, krange = nclust, criterion = \"asw\", diss = TRUE)\n    results[\"kmedoids\"] = list(kmedoids_result)\n    \n  }\n  \n  \n  # Ward method\n  if(\"ward\" %in% technique){\n    cat(\"\\nPerforming Ward hierarchical clustering...\\n\")\n    ward_result = hclust(distances, method = \"ward.D\")\n    results[\"ward\"] = list(ward_result)\n  }\n  \n  \n  # Hybrid hierarchial method\n  if(\"hybrid\" %in% technique){\n    cat(\"\\nPerforming Hybrid hierarchical clustering...\\n\")\n    hybrid_result = hybridHclust(binarydataf)  \n    results[\"hybrid\"] = list(hybrid_result)\n  }\n  \n  \n  # probability based clustering\n  \n  if(\"prob\" %in% technique){\n    library(PythonInR)\n    cat(\"\\nPerforming Bayes Bernoulli Mixture Model clustering. It might take a while depending on number of simulations...\\n\")\n    setwd(\"Python\")\n    pyConnect()\n    pyExec(\"import pandas\")\n    \n    cat(\"\\tTransferring variables to Python...\\n\")\n    pySet(\"data\", value = binarydataf, usePandas = TRUE)\n    pySet(\"nclusters\", value = max(nclust), usePandas = TRUE)\n    pySet(\"nsimulations\", value = nsim, usePandas = TRUE)\n    \n    cat(\"\\tExecuting the script...\")\n    pyExecfile(\"simpleModelbased.py\") # running \n    \n    mixtgroup = pyGet(\"modelclust\", simplify = FALSE) + 1\n    mixtprob = pyGet(\"clustprob\", simplify = TRUE)\n    mixtprototypes = pyGet(\"prototype\", simplify = TRUE)\n    \n    pyExit()\n    mixture_result = list(clusters = mixtgroup, clusterprob = mixtprob, prototypes = mixtprototypes)\n    results[\"mixture\"] = list(mixture_result)\n    \n  }\n  \n  \n  \n  #cluster.stats(distances, kmeans_result[[i]]@cluster)$avg\n  cat(\"\\n\")\n  return(results)\n  \n}\n\n\n\nconvert_dataframe = function(X){\n  \n  datafexam = data.frame(NULL) # initializing the dataframe\n  \n  for(i in 1:nrow(X)){\n    mat = X[i, 1]\n    exam = X[i, 3]\n    \n    datafexam[mat, exam] = 1\n  }\n  \n  datafexam[is.na(datafexam)] = 0 # filling the NULLs\n  \n  return(datafexam)\n}",
    "created" : 1498643147428.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "1628697905",
    "id" : "B25652B0",
    "lastKnownWriteTime" : 1496998844,
    "last_content_update" : 1496998844,
    "path" : "D:/Box Sync/#UNI/# Tesi/Analysis/ThesisAnalysis/R/external_functions.R",
    "project_path" : "R/external_functions.R",
    "properties" : {
    },
    "relative_order" : 3,
    "source_on_save" : false,
    "source_window" : "",
    "type" : "r_source"
}